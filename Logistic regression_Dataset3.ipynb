{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e879ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572b77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\dataset3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fa8adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>2.207101</td>\n",
       "      <td>0.112651</td>\n",
       "      <td>1.626798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>19.872726</td>\n",
       "      <td>2.683904</td>\n",
       "      <td>2.778303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>2.914857</td>\n",
       "      <td>1.472687</td>\n",
       "      <td>0.218075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4.258729</td>\n",
       "      <td>0.242023</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>58.108125</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>0.386920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                57.877857                        0.311140   \n",
       "1                10.829943                        0.175592   \n",
       "2                 5.091079                        0.805153   \n",
       "3                 2.247564                        5.600044   \n",
       "4                44.190936                        0.566486   \n",
       "...                    ...                             ...   \n",
       "999995            2.207101                        0.112651   \n",
       "999996           19.872726                        2.683904   \n",
       "999997            2.914857                        1.472687   \n",
       "999998            4.258729                        0.242023   \n",
       "999999           58.108125                        0.318110   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                             1.945940              1.0        1.0   \n",
       "1                             1.294219              1.0        0.0   \n",
       "2                             0.427715              1.0        0.0   \n",
       "3                             0.362663              1.0        1.0   \n",
       "4                             2.222767              1.0        1.0   \n",
       "...                                ...              ...        ...   \n",
       "999995                        1.626798              1.0        1.0   \n",
       "999996                        2.778303              1.0        1.0   \n",
       "999997                        0.218075              1.0        1.0   \n",
       "999998                        0.475822              1.0        0.0   \n",
       "999999                        0.386920              1.0        1.0   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0                   0.0           0.0    0.0  \n",
       "1                   0.0           0.0    0.0  \n",
       "2                   0.0           1.0    0.0  \n",
       "3                   0.0           1.0    0.0  \n",
       "4                   0.0           1.0    0.0  \n",
       "...                 ...           ...    ...  \n",
       "999995              0.0           0.0    0.0  \n",
       "999996              0.0           0.0    0.0  \n",
       "999997              0.0           1.0    0.0  \n",
       "999998              0.0           1.0    0.0  \n",
       "999999              0.0           1.0    0.0  \n",
       "\n",
       "[1000000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee882e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = df[[\"ratio_to_median_purchase_price\"]]\n",
    "\n",
    "# Extracting Target / Class Labels\n",
    "y = df['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Train Test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                     train_size = 0.7, \n",
    "                                     test_size = 0.3, \n",
    "                                     random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100000.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100000.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100000.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "clf = LogisticRegression(C=1e5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`logistic=True` requires statsmodels, an optional dependency, to be installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\MHC\\COMSC335\\final project\\Logistic regression_Dataset3.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MHC/COMSC335/final%20project/Logistic%20regression_Dataset3.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m θ_1\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mcoef_\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MHC/COMSC335/final%20project/Logistic%20regression_Dataset3.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#draw logisitc curve using seaborn library\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MHC/COMSC335/final%20project/Logistic%20regression_Dataset3.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m ax\u001b[39m=\u001b[39msns\u001b[39m.\u001b[39;49mregplot(x\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mratio_to_median_purchase_price\u001b[39;49m\u001b[39m\"\u001b[39;49m, y\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfraud\u001b[39;49m\u001b[39m\"\u001b[39;49m,  data\u001b[39m=\u001b[39;49mdf, logistic\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, ci\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MHC/COMSC335/final%20project/Logistic%20regression_Dataset3.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             scatter_kws\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mcolor\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mblue\u001b[39;49m\u001b[39m'\u001b[39;49m}, line_kws\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mcolor\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m#df355a\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MHC/COMSC335/final%20project/Logistic%20regression_Dataset3.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mratio_to_median_purchase_price\u001b[39m\u001b[39m\"\u001b[39m, fontsize\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MHC/COMSC335/final%20project/Logistic%20regression_Dataset3.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mfraud\u001b[39m\u001b[39m\"\u001b[39m, fontsize\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Grace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\regression.py:775\u001b[0m, in \u001b[0;36mregplot\u001b[1;34m(data, x, y, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[0;32m    773\u001b[0m scatter_kws[\u001b[39m\"\u001b[39m\u001b[39mmarker\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m marker\n\u001b[0;32m    774\u001b[0m line_kws \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m line_kws \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m copy\u001b[39m.\u001b[39mcopy(line_kws)\n\u001b[1;32m--> 775\u001b[0m plotter\u001b[39m.\u001b[39;49mplot(ax, scatter_kws, line_kws)\n\u001b[0;32m    776\u001b[0m \u001b[39mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32mc:\\Users\\Grace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\regression.py:384\u001b[0m, in \u001b[0;36m_RegressionPlotter.plot\u001b[1;34m(self, ax, scatter_kws, line_kws)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscatterplot(ax, scatter_kws)\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_reg:\n\u001b[1;32m--> 384\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlineplot(ax, line_kws)\n\u001b[0;32m    386\u001b[0m \u001b[39m# Label the axes\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Grace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\regression.py:429\u001b[0m, in \u001b[0;36m_RegressionPlotter.lineplot\u001b[1;34m(self, ax, kws)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Draw the model.\"\"\"\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[39m# Fit the regression model\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m grid, yhat, err_bands \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_regression(ax)\n\u001b[0;32m    430\u001b[0m edges \u001b[39m=\u001b[39m grid[\u001b[39m0\u001b[39m], grid[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    432\u001b[0m \u001b[39m# Get set default aesthetics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Grace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\regression.py:198\u001b[0m, in \u001b[0;36m_RegressionPlotter.fit_regression\u001b[1;34m(self, ax, x_range, grid)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_regression\u001b[39m(\u001b[39mself\u001b[39m, ax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, x_range\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, grid\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    197\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the regression model.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_statsmodels()\n\u001b[0;32m    200\u001b[0m     \u001b[39m# Create the grid for the regression\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m grid \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Grace\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\regression.py:194\u001b[0m, in \u001b[0;36m_RegressionPlotter._check_statsmodels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mfor\u001b[39;00m option \u001b[39min\u001b[39;00m options:\n\u001b[0;32m    193\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, option) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_statsmodels:\n\u001b[1;32m--> 194\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(err\u001b[39m.\u001b[39mformat(option))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: `logistic=True` requires statsmodels, an optional dependency, to be installed."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df[[\"ratio_to_median_purchase_price\"]]\n",
    "y = df[\"fraud\"]\n",
    "\n",
    "x=x.to_numpy().reshape(-1,1)\n",
    "y=y.to_numpy()\n",
    "\n",
    "θ_o=clf.intercept_\n",
    "θ_1=clf.coef_\n",
    "\n",
    "#draw logisitc curve using seaborn library\n",
    "ax=sns.regplot(x=\"ratio_to_median_purchase_price\", y=\"fraud\",  data=df, logistic=True, ci=None, \n",
    "            scatter_kws={'color': 'blue'}, line_kws={'color': '#df355a'})\n",
    "\n",
    "plt.xlabel(\"ratio_to_median_purchase_price\", fontsize=12)\n",
    "plt.ylabel(\"fraud\", fontsize=12)\n",
    "\n",
    "print(θ_o)\n",
    "print(θ_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[630449   8277]\n",
      " [ 47132  14142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96    638726\n",
      "         1.0       0.63      0.23      0.34     61274\n",
      "\n",
      "    accuracy                           0.92    700000\n",
      "   macro avg       0.78      0.61      0.65    700000\n",
      "weighted avg       0.90      0.92      0.90    700000\n",
      "\n",
      "0.9208442857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#evaluation on training data\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[270323   3548]\n",
      " [ 20122   6007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96    273871\n",
      "         1.0       0.63      0.23      0.34     26129\n",
      "\n",
      "    accuracy                           0.92    300000\n",
      "   macro avg       0.78      0.61      0.65    300000\n",
      "weighted avg       0.90      0.92      0.90    300000\n",
      "\n",
      "0.9211\n"
     ]
    }
   ],
   "source": [
    "#evaluation on test data\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
