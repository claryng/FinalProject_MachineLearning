{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fdb5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of evaluating a decision tree with random undersampling\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec09b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
       "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
       "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
       "       'merch_lat', 'merch_long', 'is_fraud', 'Time', 'Recorded_times',\n",
       "       'Categorized_times', 'Categorized_trasaction_purpose'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\processed_dataset1.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.472\n",
      "\n",
      "Training dataset:\n",
      "[[172178 215315]\n",
      " [   654    856]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61    387493\n",
      "           1       0.00      0.57      0.01      1510\n",
      "\n",
      "    accuracy                           0.44    389003\n",
      "   macro avg       0.50      0.51      0.31    389003\n",
      "weighted avg       0.99      0.44      0.61    389003\n",
      "\n",
      "\n",
      "Testing dataset:\n",
      "[[74119 91962]\n",
      " [  286   349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62    166081\n",
      "           1       0.00      0.55      0.01       635\n",
      "\n",
      "    accuracy                           0.45    166716\n",
      "   macro avg       0.50      0.50      0.31    166716\n",
      "weighted avg       0.99      0.45      0.61    166716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# define dataset\n",
    "X = np.array(df[['lat','long']].to_numpy()) \n",
    "y = df[\"is_fraud\"]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                     train_size = 0.7, \n",
    "                                     test_size = 0.3, \n",
    "                                     random_state = 70)\n",
    "\n",
    "# define pipeline\n",
    "steps = [('under', RandomUnderSampler()), ('model', LogisticRegression())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "clf = pipeline.fit(X,y)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)\n",
    "print()\n",
    "#evaluation on training data\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(\"Training dataset:\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print()\n",
    "\n",
    "#evaluation on test data\n",
    "print(\"Testing dataset:\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17d558b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.771\n",
      "\n",
      "Training dataset:\n",
      "[[299103  88390]\n",
      " [    21   1489]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87    387493\n",
      "           1       0.02      0.99      0.03      1510\n",
      "\n",
      "    accuracy                           0.77    389003\n",
      "   macro avg       0.51      0.88      0.45    389003\n",
      "weighted avg       1.00      0.77      0.87    389003\n",
      "\n",
      "\n",
      "Testing dataset:\n",
      "[[127985  38096]\n",
      " [     8    627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87    166081\n",
      "           1       0.02      0.99      0.03       635\n",
      "\n",
      "    accuracy                           0.77    166716\n",
      "   macro avg       0.51      0.88      0.45    166716\n",
      "weighted avg       1.00      0.77      0.87    166716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "# define dataset\n",
    "# X = np.array(df[['cc_num','amt','zip','lat','long','city_pop','merch_lat','merch_long']].to_numpy()) # F1 = 0.862\n",
    "# X = np.array(df[['amt','lat','long','city_pop','merch_lat','merch_long']].to_numpy()) # F1 = 0.862\n",
    "X = np.array(df[['lat','long']].to_numpy()) # F1 = 0.770\n",
    "y = df[\"is_fraud\"]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                     train_size = 0.7, \n",
    "                                     test_size = 0.3, \n",
    "                                     random_state = 70)\n",
    "\n",
    "# define pipeline\n",
    "steps = [('under', RandomUnderSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "clf = pipeline.fit(X,y)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)\n",
    "print()\n",
    "#evaluation on training data\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(\"Training dataset:\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print()\n",
    "\n",
    "#evaluation on test data\n",
    "print(\"Testing dataset:\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec574161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.777\n",
      "\n",
      "Training dataset:\n",
      "[[307097  80396]\n",
      " [   372   1138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88    387493\n",
      "           1       0.01      0.75      0.03      1510\n",
      "\n",
      "    accuracy                           0.79    389003\n",
      "   macro avg       0.51      0.77      0.46    389003\n",
      "weighted avg       0.99      0.79      0.88    389003\n",
      "\n",
      "\n",
      "[[131536  34545]\n",
      " [   155    480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88    166081\n",
      "           1       0.01      0.76      0.03       635\n",
      "\n",
      "    accuracy                           0.79    166716\n",
      "   macro avg       0.51      0.77      0.46    166716\n",
      "weighted avg       1.00      0.79      0.88    166716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "X = np.array(df[['lat','long']].to_numpy()) # F1 = 0.770\n",
    "y = df[\"is_fraud\"]\n",
    "\n",
    "# Train Test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                     train_size = 0.7, \n",
    "                                     test_size = 0.3, \n",
    "                                     random_state = 70)\n",
    "\n",
    "# define pipeline\n",
    "steps = [('under', RandomUnderSampler()), ('model', neighbors.KNeighborsClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "clf = pipeline.fit(X,y)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)\n",
    "print()\n",
    "\n",
    "#evaluation on training data\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(\"Training dataset:\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print()\n",
    "\n",
    "#evaluation on test data\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f29c7a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.777\n",
      "\n",
      "Training dataset:\n",
      "[[300134  87359]\n",
      " [    17   1493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87    387493\n",
      "           1       0.02      0.99      0.03      1510\n",
      "\n",
      "    accuracy                           0.78    389003\n",
      "   macro avg       0.51      0.88      0.45    389003\n",
      "weighted avg       1.00      0.78      0.87    389003\n",
      "\n",
      "\n",
      "[[128404  37677]\n",
      " [     8    627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87    166081\n",
      "           1       0.02      0.99      0.03       635\n",
      "\n",
      "    accuracy                           0.77    166716\n",
      "   macro avg       0.51      0.88      0.45    166716\n",
      "weighted avg       1.00      0.77      0.87    166716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "X = np.array(df[['lat','long']].to_numpy()) # F1 = 0.770\n",
    "y = df[\"is_fraud\"]\n",
    "\n",
    "# Train Test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                     train_size = 0.7, \n",
    "                                     test_size = 0.3, \n",
    "                                     random_state = 70)\n",
    "\n",
    "# define pipeline\n",
    "steps = [('under', RandomUnderSampler()), ('model', RandomForestClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "clf = pipeline.fit(X,y)\n",
    "\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)\n",
    "print()\n",
    "\n",
    "#evaluation on training data\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(\"Training dataset:\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print()\n",
    "\n",
    "#evaluation on test data\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027beaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
